# ç¬¬8ç« ï¼šéƒ¨ç½²ä¸ä¼˜åŒ–

## ğŸ¯ æœ¬ç« ç›®æ ‡

åœ¨è¿™ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†ï¼š
- é…ç½® Docker å®¹å™¨åŒ–éƒ¨ç½²
- è®¾ç½® CI/CD æµæ°´çº¿
- å®ç°ç”Ÿäº§ç¯å¢ƒé…ç½®
- è¿›è¡Œæ€§èƒ½ä¼˜åŒ–
- é…ç½®ç›‘æ§å’Œæ—¥å¿—
- å®ç°ç¼“å­˜ç­–ç•¥
- è®¾ç½®è´Ÿè½½å‡è¡¡å’Œé«˜å¯ç”¨

## ğŸ³ Docker å®¹å™¨åŒ–

### 1. Dockerfile é…ç½®

```dockerfile
# Dockerfile
# ä½¿ç”¨å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–é•œåƒå¤§å°
FROM node:18-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ package æ–‡ä»¶
COPY package*.json ./
COPY prisma ./prisma/

# å®‰è£…ä¾èµ–
RUN npm ci --only=production && npm cache clean --force

# å¤åˆ¶æºä»£ç 
COPY . .

# ç”Ÿæˆ Prisma å®¢æˆ·ç«¯
RUN npx prisma generate

# æ„å»ºåº”ç”¨
RUN npm run build

# ç”Ÿäº§é˜¶æ®µ
FROM node:18-alpine AS production

# åˆ›å»ºé root ç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nestjs -u 1001

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶æ„å»ºäº§ç‰©å’Œä¾èµ–
COPY --from=builder --chown=nestjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nestjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nestjs:nodejs /app/prisma ./prisma
COPY --from=builder --chown=nestjs:nodejs /app/package*.json ./

# åˆ›å»ºä¸Šä¼ ç›®å½•
RUN mkdir -p /app/uploads && chown -R nestjs:nodejs /app/uploads

# åˆ‡æ¢åˆ°é root ç”¨æˆ·
USER nestjs

# æš´éœ²ç«¯å£
EXPOSE 3000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

# å¯åŠ¨åº”ç”¨
CMD ["node", "dist/main"]
```

### 2. Docker Compose é…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  # åº”ç”¨æœåŠ¡
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=mysql://nestjs:password@db:3306/blog_prod
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=${JWT_SECRET}
      - JWT_REFRESH_SECRET=${JWT_REFRESH_SECRET}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - uploads:/app/uploads
      - logs:/app/logs
    restart: unless-stopped
    networks:
      - app-network

  # æ•°æ®åº“æœåŠ¡
  db:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=rootpassword
      - MYSQL_DATABASE=blog_prod
      - MYSQL_USER=nestjs
      - MYSQL_PASSWORD=password
    ports:
      - "3306:3306"
    volumes:
      - db_data:/var/lib/mysql
      - ./docker/mysql/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10
    restart: unless-stopped
    networks:
      - app-network

  # Redis ç¼“å­˜æœåŠ¡
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      timeout: 3s
      retries: 5
    restart: unless-stopped
    networks:
      - app-network

  # Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./docker/nginx/ssl:/etc/nginx/ssl
      - uploads:/var/www/uploads
    depends_on:
      - app
    restart: unless-stopped
    networks:
      - app-network

volumes:
  db_data:
  redis_data:
  uploads:
  logs:

networks:
  app-network:
    driver: bridge
```

### 3. å¼€å‘ç¯å¢ƒ Docker Compose

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
      - "9229:9229"  # è°ƒè¯•ç«¯å£
    environment:
      - NODE_ENV=development
      - DATABASE_URL=mysql://nestjs:password@db:3306/blog_dev
      - REDIS_URL=redis://redis:6379
    volumes:
      - .:/app
      - /app/node_modules
      - uploads:/app/uploads
    depends_on:
      - db
      - redis
    networks:
      - app-network

  db:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=rootpassword
      - MYSQL_DATABASE=blog_dev
      - MYSQL_USER=nestjs
      - MYSQL_PASSWORD=password
    ports:
      - "3306:3306"
    volumes:
      - db_dev_data:/var/lib/mysql
    networks:
      - app-network

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    networks:
      - app-network

volumes:
  db_dev_data:
  uploads:

networks:
  app-network:
    driver: bridge
```

### 4. å¼€å‘ç¯å¢ƒ Dockerfile

```dockerfile
# Dockerfile.dev
FROM node:18-alpine

# å®‰è£…å¼€å‘å·¥å…·
RUN apk add --no-cache curl

WORKDIR /app

# å¤åˆ¶ package æ–‡ä»¶
COPY package*.json ./
COPY prisma ./prisma/

# å®‰è£…æ‰€æœ‰ä¾èµ–ï¼ˆåŒ…æ‹¬å¼€å‘ä¾èµ–ï¼‰
RUN npm install

# ç”Ÿæˆ Prisma å®¢æˆ·ç«¯
RUN npx prisma generate

# å¤åˆ¶æºä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 3000 9229

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
CMD ["npm", "run", "start:dev"]
```

## âš™ï¸ Nginx é…ç½®

### 1. Nginx ä¸»é…ç½®

```nginx
# docker/nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # åŸºæœ¬è®¾ç½®
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 10M;

    # Gzip å‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # ä¸Šæ¸¸æœåŠ¡å™¨
    upstream nestjs_backend {
        server app:3000;
        keepalive 32;
    }

    # é™æµé…ç½®
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;

    server {
        listen 80;
        server_name localhost;

        # é‡å®šå‘åˆ° HTTPS
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name localhost;

        # SSL é…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;

        # å®‰å…¨å¤´
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload";

        # API è·¯ç”±
        location /api {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://nestjs_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_read_timeout 86400;
        }

        # ç™»å½•æ¥å£ç‰¹æ®Šé™æµ
        location /api/auth/login {
            limit_req zone=login burst=5 nodelay;
            
            proxy_pass http://nestjs_backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # é™æ€æ–‡ä»¶æœåŠ¡
        location /uploads {
            alias /var/www/uploads;
            expires 1y;
            add_header Cache-Control "public, immutable";
            
            # å›¾ç‰‡ä¼˜åŒ–
            location ~* \.(jpg|jpeg|png|gif|webp)$ {
                expires 1y;
                add_header Cache-Control "public, immutable";
                add_header Vary Accept;
            }
        }

        # API æ–‡æ¡£
        location /api-docs {
            proxy_pass http://nestjs_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # å¥åº·æ£€æŸ¥
        location /health {
            proxy_pass http://nestjs_backend;
            access_log off;
        }

        # é»˜è®¤è·¯ç”±
        location / {
            return 404;
        }
    }
}
```

## ğŸš€ CI/CD æµæ°´çº¿

### 1. GitHub Actions é…ç½®

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  NODE_VERSION: '18'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ä»£ç è´¨é‡æ£€æŸ¥
  lint-and-test:
    runs-on: ubuntu-latest

    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: rootpassword
          MYSQL_DATABASE: blog_test
          MYSQL_USER: nestjs
          MYSQL_PASSWORD: password
        ports:
          - 3306:3306
        options: >-
          --health-cmd="mysqladmin ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd="redis-cli ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Generate Prisma client
      run: npx prisma generate

    - name: Run database migrations
      run: npx prisma migrate deploy
      env:
        DATABASE_URL: mysql://nestjs:password@localhost:3306/blog_test

    - name: Lint code
      run: npm run lint

    - name: Run unit tests
      run: npm run test:cov
      env:
        DATABASE_URL: mysql://nestjs:password@localhost:3306/blog_test
        REDIS_URL: redis://localhost:6379

    - name: Run integration tests
      run: npm run test:e2e
      env:
        DATABASE_URL: mysql://nestjs:password@localhost:3306/blog_test
        REDIS_URL: redis://localhost:6379

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage/lcov.info
        flags: unittests
        name: codecov-umbrella

  # å®‰å…¨æ‰«æ
  security-scan:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  # æ„å»ºå’Œæ¨é€ Docker é•œåƒ
  build-and-push:
    needs: [lint-and-test, security-scan]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    permissions:
      contents: read
      packages: write

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
    - name: Deploy to production
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.PROD_HOST }}
        username: ${{ secrets.PROD_USER }}
        key: ${{ secrets.PROD_SSH_KEY }}
        script: |
          cd /opt/blog-app
          docker-compose pull
          docker-compose up -d --remove-orphans
          docker system prune -f
```

### 2. éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

echo "ğŸš€ å¼€å§‹éƒ¨ç½²..."

# æ£€æŸ¥ç¯å¢ƒå˜é‡
if [ -z "$ENVIRONMENT" ]; then
    echo "âŒ è¯·è®¾ç½® ENVIRONMENT ç¯å¢ƒå˜é‡"
    exit 1
fi

# è®¾ç½®å˜é‡
COMPOSE_FILE="docker-compose.yml"
if [ "$ENVIRONMENT" = "staging" ]; then
    COMPOSE_FILE="docker-compose.staging.yml"
fi

echo "ğŸ“¦ æ‹‰å–æœ€æ–°é•œåƒ..."
docker-compose -f $COMPOSE_FILE pull

echo "ğŸ”„ æ›´æ–°æœåŠ¡..."
docker-compose -f $COMPOSE_FILE up -d --remove-orphans

echo "ğŸ§¹ æ¸…ç†æ—§é•œåƒ..."
docker image prune -f

echo "ğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
docker-compose -f $COMPOSE_FILE ps

echo "âœ… éƒ¨ç½²å®Œæˆï¼"

# å¥åº·æ£€æŸ¥
echo "ğŸ¥ æ‰§è¡Œå¥åº·æ£€æŸ¥..."
sleep 10
if curl -f http://localhost/health; then
    echo "âœ… å¥åº·æ£€æŸ¥é€šè¿‡"
else
    echo "âŒ å¥åº·æ£€æŸ¥å¤±è´¥"
    exit 1
fi
```

### 3. æ•°æ®åº“è¿ç§»è„šæœ¬

```bash
#!/bin/bash
# scripts/migrate.sh

set -e

echo "ğŸ—„ï¸ å¼€å§‹æ•°æ®åº“è¿ç§»..."

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
echo "ğŸ” æ£€æŸ¥æ•°æ®åº“è¿æ¥..."
if ! docker-compose exec db mysqladmin ping -h localhost --silent; then
    echo "âŒ æ•°æ®åº“è¿æ¥å¤±è´¥"
    exit 1
fi

# å¤‡ä»½æ•°æ®åº“
echo "ğŸ’¾ å¤‡ä»½æ•°æ®åº“..."
BACKUP_FILE="backup_$(date +%Y%m%d_%H%M%S).sql"
docker-compose exec db mysqldump -u root -p$MYSQL_ROOT_PASSWORD blog_prod > backups/$BACKUP_FILE
echo "âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ: $BACKUP_FILE"

# è¿è¡Œè¿ç§»
echo "ğŸ”„ è¿è¡Œæ•°æ®åº“è¿ç§»..."
docker-compose exec app npx prisma migrate deploy

# éªŒè¯è¿ç§»
echo "ğŸ” éªŒè¯è¿ç§»ç»“æœ..."
docker-compose exec app npx prisma migrate status

echo "âœ… æ•°æ®åº“è¿ç§»å®Œæˆï¼"
```

## ğŸ”§ ç”Ÿäº§ç¯å¢ƒé…ç½®

### 1. ç”Ÿäº§ç¯å¢ƒå˜é‡

```bash
# .env.production
NODE_ENV=production

# åº”ç”¨é…ç½®
APP_PORT=3000
APP_URL=https://api.yourdomain.com

# æ•°æ®åº“é…ç½®
DATABASE_URL=mysql://nestjs:${DB_PASSWORD}@db:3306/blog_prod

# Redis é…ç½®
REDIS_URL=redis://redis:6379

# JWT é…ç½®
JWT_SECRET=${JWT_SECRET}
JWT_REFRESH_SECRET=${JWT_REFRESH_SECRET}
JWT_ACCESS_TOKEN_EXPIRATION=15m
JWT_REFRESH_TOKEN_EXPIRATION=7d

# é‚®ä»¶é…ç½®
MAIL_HOST=smtp.gmail.com
MAIL_PORT=587
MAIL_SECURE=false
MAIL_USER=${MAIL_USER}
MAIL_PASSWORD=${MAIL_PASSWORD}
MAIL_FROM=noreply@yourdomain.com

# æ–‡ä»¶ä¸Šä¼ é…ç½®
UPLOAD_PATH=/app/uploads
UPLOAD_MAX_SIZE=10485760

# æ—¥å¿—é…ç½®
LOG_LEVEL=info
LOG_FILE_PATH=/app/logs

# ç›‘æ§é…ç½®
SENTRY_DSN=${SENTRY_DSN}
PROMETHEUS_ENABLED=true
PROMETHEUS_PORT=9090

# ç¼“å­˜é…ç½®
CACHE_TTL=300
CACHE_MAX_ITEMS=1000

# é™æµé…ç½®
THROTTLE_TTL=60
THROTTLE_LIMIT=100

# CORS é…ç½®
CORS_ORIGIN=https://yourdomain.com
CORS_CREDENTIALS=true
```

### 2. ç”Ÿäº§ç¯å¢ƒé…ç½®ç±»

```typescript
// src/config/production.config.ts
import { registerAs } from '@nestjs/config';

export default registerAs('production', () => ({
  // æ€§èƒ½é…ç½®
  performance: {
    enableCompression: true,
    enableCaching: true,
    cacheMaxAge: parseInt(process.env.CACHE_MAX_AGE) || 3600,
    enableCluster: process.env.ENABLE_CLUSTER === 'true',
    workerProcesses: parseInt(process.env.WORKER_PROCESSES) || require('os').cpus().length,
  },

  // å®‰å…¨é…ç½®
  security: {
    enableHelmet: true,
    enableCors: true,
    enableRateLimit: true,
    rateLimitWindowMs: parseInt(process.env.RATE_LIMIT_WINDOW_MS) || 900000, // 15åˆ†é’Ÿ
    rateLimitMax: parseInt(process.env.RATE_LIMIT_MAX) || 100,
    enableCsrf: process.env.ENABLE_CSRF === 'true',
    trustProxy: process.env.TRUST_PROXY === 'true',
  },

  // ç›‘æ§é…ç½®
  monitoring: {
    enableMetrics: process.env.ENABLE_METRICS === 'true',
    enableTracing: process.env.ENABLE_TRACING === 'true',
    enableHealthCheck: true,
    metricsPath: process.env.METRICS_PATH || '/metrics',
    healthCheckPath: process.env.HEALTH_CHECK_PATH || '/health',
  },

  // æ—¥å¿—é…ç½®
  logging: {
    level: process.env.LOG_LEVEL || 'info',
    enableFileLogging: true,
    enableConsoleLogging: true,
    logFilePath: process.env.LOG_FILE_PATH || './logs',
    maxFiles: parseInt(process.env.LOG_MAX_FILES) || 14,
    maxSize: process.env.LOG_MAX_SIZE || '20m',
  },

  // æ•°æ®åº“é…ç½®
  database: {
    connectionLimit: parseInt(process.env.DB_CONNECTION_LIMIT) || 10,
    acquireTimeout: parseInt(process.env.DB_ACQUIRE_TIMEOUT) || 60000,
    timeout: parseInt(process.env.DB_TIMEOUT) || 60000,
    enableLogging: process.env.DB_ENABLE_LOGGING === 'true',
  },

  // ç¼“å­˜é…ç½®
  cache: {
    ttl: parseInt(process.env.CACHE_TTL) || 300,
    maxItems: parseInt(process.env.CACHE_MAX_ITEMS) || 1000,
    enableRedis: process.env.ENABLE_REDIS_CACHE === 'true',
  },
}));
```

### 3. å¥åº·æ£€æŸ¥æœåŠ¡

```typescript
// src/health/health.controller.ts
import { Controller, Get } from '@nestjs/common';
import { ApiTags, ApiOperation, ApiResponse } from '@nestjs/swagger';
import {
  HealthCheckService,
  HealthCheck,
  TypeOrmHealthIndicator,
  MemoryHealthIndicator,
  DiskHealthIndicator,
} from '@nestjs/terminus';
import { PrismaHealthIndicator } from './prisma-health.indicator';
import { RedisHealthIndicator } from './redis-health.indicator';
import { Public } from '../common/decorators/public.decorator';

@ApiTags('å¥åº·æ£€æŸ¥')
@Controller('health')
export class HealthController {
  constructor(
    private health: HealthCheckService,
    private prismaHealth: PrismaHealthIndicator,
    private redisHealth: RedisHealthIndicator,
    private memory: MemoryHealthIndicator,
    private disk: DiskHealthIndicator,
  ) {}

  @Get()
  @Public()
  @ApiOperation({ summary: 'å¥åº·æ£€æŸ¥' })
  @ApiResponse({ status: 200, description: 'æœåŠ¡å¥åº·' })
  @ApiResponse({ status: 503, description: 'æœåŠ¡ä¸å¥åº·' })
  @HealthCheck()
  check() {
    return this.health.check([
      // æ•°æ®åº“å¥åº·æ£€æŸ¥
      () => this.prismaHealth.isHealthy('database'),

      // Redis å¥åº·æ£€æŸ¥
      () => this.redisHealth.isHealthy('redis'),

      // å†…å­˜ä½¿ç”¨æ£€æŸ¥
      () => this.memory.checkHeap('memory_heap', 150 * 1024 * 1024),
      () => this.memory.checkRSS('memory_rss', 150 * 1024 * 1024),

      // ç£ç›˜ç©ºé—´æ£€æŸ¥
      () => this.disk.checkStorage('storage', {
        path: '/',
        thresholdPercent: 0.9,
      }),
    ]);
  }

  @Get('ready')
  @Public()
  @ApiOperation({ summary: 'å°±ç»ªæ£€æŸ¥' })
  @HealthCheck()
  ready() {
    return this.health.check([
      () => this.prismaHealth.isHealthy('database'),
      () => this.redisHealth.isHealthy('redis'),
    ]);
  }

  @Get('live')
  @Public()
  @ApiOperation({ summary: 'å­˜æ´»æ£€æŸ¥' })
  live() {
    return {
      status: 'ok',
      timestamp: new Date().toISOString(),
      uptime: process.uptime(),
      memory: process.memoryUsage(),
    };
  }
}
```

### 4. Prisma å¥åº·æ£€æŸ¥æŒ‡ç¤ºå™¨

```typescript
// src/health/prisma-health.indicator.ts
import { Injectable } from '@nestjs/common';
import { HealthIndicator, HealthIndicatorResult, HealthCheckError } from '@nestjs/terminus';
import { PrismaService } from '../prisma/prisma.service';

@Injectable()
export class PrismaHealthIndicator extends HealthIndicator {
  constructor(private prisma: PrismaService) {
    super();
  }

  async isHealthy(key: string): Promise<HealthIndicatorResult> {
    try {
      await this.prisma.$queryRaw`SELECT 1`;
      return this.getStatus(key, true);
    } catch (error) {
      throw new HealthCheckError('Prisma check failed', this.getStatus(key, false));
    }
  }
}
```

### 5. Redis å¥åº·æ£€æŸ¥æŒ‡ç¤ºå™¨

```typescript
// src/health/redis-health.indicator.ts
import { Injectable } from '@nestjs/common';
import { HealthIndicator, HealthIndicatorResult, HealthCheckError } from '@nestjs/terminus';
import { ConfigService } from '@nestjs/config';
import Redis from 'ioredis';

@Injectable()
export class RedisHealthIndicator extends HealthIndicator {
  private redis: Redis;

  constructor(private configService: ConfigService) {
    super();
    this.redis = new Redis(this.configService.get('redis.url'));
  }

  async isHealthy(key: string): Promise<HealthIndicatorResult> {
    try {
      await this.redis.ping();
      return this.getStatus(key, true);
    } catch (error) {
      throw new HealthCheckError('Redis check failed', this.getStatus(key, false));
    }
  }
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å­˜ç­–ç•¥å®ç°

```typescript
// src/cache/redis-cache.service.ts
import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import Redis from 'ioredis';

@Injectable()
export class RedisCacheService {
  private readonly logger = new Logger(RedisCacheService.name);
  private redis: Redis;

  constructor(private configService: ConfigService) {
    this.redis = new Redis(this.configService.get('redis.url'), {
      retryDelayOnFailover: 100,
      enableReadyCheck: false,
      maxRetriesPerRequest: null,
    });

    this.redis.on('connect', () => {
      this.logger.log('Redis connected');
    });

    this.redis.on('error', (error) => {
      this.logger.error('Redis connection error:', error);
    });
  }

  async get<T>(key: string): Promise<T | null> {
    try {
      const value = await this.redis.get(key);
      return value ? JSON.parse(value) : null;
    } catch (error) {
      this.logger.error(`Cache get error for key ${key}:`, error);
      return null;
    }
  }

  async set(key: string, value: any, ttl?: number): Promise<void> {
    try {
      const serialized = JSON.stringify(value);
      if (ttl) {
        await this.redis.setex(key, ttl, serialized);
      } else {
        await this.redis.set(key, serialized);
      }
    } catch (error) {
      this.logger.error(`Cache set error for key ${key}:`, error);
    }
  }

  async del(key: string): Promise<void> {
    try {
      await this.redis.del(key);
    } catch (error) {
      this.logger.error(`Cache delete error for key ${key}:`, error);
    }
  }

  async delPattern(pattern: string): Promise<void> {
    try {
      const keys = await this.redis.keys(pattern);
      if (keys.length > 0) {
        await this.redis.del(...keys);
      }
    } catch (error) {
      this.logger.error(`Cache delete pattern error for pattern ${pattern}:`, error);
    }
  }

  async exists(key: string): Promise<boolean> {
    try {
      const result = await this.redis.exists(key);
      return result === 1;
    } catch (error) {
      this.logger.error(`Cache exists error for key ${key}:`, error);
      return false;
    }
  }

  async ttl(key: string): Promise<number> {
    try {
      return await this.redis.ttl(key);
    } catch (error) {
      this.logger.error(`Cache TTL error for key ${key}:`, error);
      return -1;
    }
  }
}
```

### 2. æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–

```typescript
// src/common/decorators/cache.decorator.ts
import { SetMetadata } from '@nestjs/common';

export const CACHE_KEY_METADATA = 'cache_key';
export const CACHE_TTL_METADATA = 'cache_ttl';

export const CacheResult = (key: string, ttl: number = 300) => {
  return (target: any, propertyName: string, descriptor: PropertyDescriptor) => {
    SetMetadata(CACHE_KEY_METADATA, key)(target, propertyName, descriptor);
    SetMetadata(CACHE_TTL_METADATA, ttl)(target, propertyName, descriptor);
  };
};
```

```typescript
// src/common/interceptors/cache-result.interceptor.ts
import {
  Injectable,
  NestInterceptor,
  ExecutionContext,
  CallHandler,
} from '@nestjs/common';
import { Reflector } from '@nestjs/core';
import { Observable, of } from 'rxjs';
import { tap } from 'rxjs/operators';
import { RedisCacheService } from '../../cache/redis-cache.service';
import { CACHE_KEY_METADATA, CACHE_TTL_METADATA } from '../decorators/cache.decorator';

@Injectable()
export class CacheResultInterceptor implements NestInterceptor {
  constructor(
    private cacheService: RedisCacheService,
    private reflector: Reflector,
  ) {}

  async intercept(
    context: ExecutionContext,
    next: CallHandler,
  ): Promise<Observable<any>> {
    const cacheKey = this.reflector.get<string>(
      CACHE_KEY_METADATA,
      context.getHandler(),
    );
    const cacheTTL = this.reflector.get<number>(
      CACHE_TTL_METADATA,
      context.getHandler(),
    );

    if (!cacheKey) {
      return next.handle();
    }

    const request = context.switchToHttp().getRequest();
    const fullCacheKey = this.generateCacheKey(cacheKey, request);

    // å°è¯•ä»ç¼“å­˜è·å–
    const cachedResult = await this.cacheService.get(fullCacheKey);
    if (cachedResult) {
      return of(cachedResult);
    }

    // æ‰§è¡ŒåŸæ–¹æ³•å¹¶ç¼“å­˜ç»“æœ
    return next.handle().pipe(
      tap(async (result) => {
        await this.cacheService.set(fullCacheKey, result, cacheTTL);
      }),
    );
  }

  private generateCacheKey(baseKey: string, request: any): string {
    const { method, url, query, params, user } = request;
    const userId = user?.id || 'anonymous';
    const queryString = JSON.stringify(query);
    const paramsString = JSON.stringify(params);
    return `${baseKey}:${method}:${url}:${userId}:${queryString}:${paramsString}`;
  }
}
```

### 3. æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–

```typescript
// src/prisma/prisma.service.ts (ä¼˜åŒ–ç‰ˆæœ¬)
import { Injectable, OnModuleInit, OnModuleDestroy, Logger } from '@nestjs/common';
import { PrismaClient } from '@prisma/client';
import { ConfigService } from '@nestjs/config';

@Injectable()
export class PrismaService extends PrismaClient implements OnModuleInit, OnModuleDestroy {
  private readonly logger = new Logger(PrismaService.name);

  constructor(private configService: ConfigService) {
    super({
      datasources: {
        db: {
          url: configService.get('database.url'),
        },
      },
      log: configService.get('database.enableLogging')
        ? ['query', 'info', 'warn', 'error']
        : ['error'],
    });

    // æŸ¥è¯¢æ€§èƒ½ç›‘æ§
    this.$use(async (params, next) => {
      const before = Date.now();
      const result = await next(params);
      const after = Date.now();

      const duration = after - before;
      if (duration > 1000) { // è¶…è¿‡1ç§’çš„æ…¢æŸ¥è¯¢
        this.logger.warn(`Slow query detected: ${params.model}.${params.action} took ${duration}ms`);
      }

      return result;
    });
  }

  async onModuleInit() {
    try {
      await this.$connect();
      this.logger.log('Database connected successfully');
    } catch (error) {
      this.logger.error('Database connection failed:', error);
      throw error;
    }
  }

  async onModuleDestroy() {
    await this.$disconnect();
    this.logger.log('Database disconnected');
  }

  // æ‰¹é‡æ“ä½œä¼˜åŒ–
  async batchCreate<T>(model: string, data: any[]): Promise<T[]> {
    const batchSize = 100;
    const results = [];

    for (let i = 0; i < data.length; i += batchSize) {
      const batch = data.slice(i, i + batchSize);
      const batchResult = await (this as any)[model].createMany({
        data: batch,
        skipDuplicates: true,
      });
      results.push(batchResult);
    }

    return results;
  }

  // äº‹åŠ¡ä¼˜åŒ–
  async executeTransaction<T>(operations: (tx: PrismaClient) => Promise<T>): Promise<T> {
    return this.$transaction(operations, {
      maxWait: 5000, // æœ€å¤§ç­‰å¾…æ—¶é—´
      timeout: 10000, // äº‹åŠ¡è¶…æ—¶æ—¶é—´
    });
  }
}
```

### 4. å“åº”å‹ç¼©å’Œé™æ€èµ„æºä¼˜åŒ–

```typescript
// src/main.ts (ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–)
import { NestFactory } from '@nestjs/core';
import { ValidationPipe } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { DocumentBuilder, SwaggerModule } from '@nestjs/swagger';
import { AppModule } from './app.module';
import * as compression from 'compression';
import helmet from 'helmet';
import { Logger } from '@nestjs/common';

async function bootstrap() {
  const app = await NestFactory.create(AppModule, {
    logger: ['error', 'warn', 'log'],
  });

  const configService = app.get(ConfigService);
  const logger = new Logger('Bootstrap');

  // å®‰å…¨ä¸­é—´ä»¶
  app.use(helmet({
    contentSecurityPolicy: {
      directives: {
        defaultSrc: ["'self'"],
        styleSrc: ["'self'", "'unsafe-inline'"],
        scriptSrc: ["'self'"],
        imgSrc: ["'self'", "data:", "https:"],
      },
    },
  }));

  // å¯ç”¨å‹ç¼©
  app.use(compression({
    filter: (req, res) => {
      if (req.headers['x-no-compression']) {
        return false;
      }
      return compression.filter(req, res);
    },
    threshold: 1024, // åªå‹ç¼©å¤§äº1KBçš„å“åº”
  }));

  // CORS é…ç½®
  app.enableCors({
    origin: configService.get('cors.origin'),
    credentials: configService.get('cors.credentials'),
    methods: ['GET', 'POST', 'PUT', 'DELETE', 'PATCH'],
    allowedHeaders: ['Content-Type', 'Authorization'],
  });

  // å…¨å±€éªŒè¯ç®¡é“
  app.useGlobalPipes(
    new ValidationPipe({
      whitelist: true,
      forbidNonWhitelisted: true,
      transform: true,
      transformOptions: {
        enableImplicitConversion: true,
      },
    }),
  );

  // ä¿¡ä»»ä»£ç†
  if (configService.get('production.security.trustProxy')) {
    app.set('trust proxy', 1);
  }

  // Swagger é…ç½®ï¼ˆä»…åœ¨éç”Ÿäº§ç¯å¢ƒï¼‰
  if (process.env.NODE_ENV !== 'production') {
    const config = new DocumentBuilder()
      .setTitle('NestJS åšå®¢ API')
      .setDescription('API æ–‡æ¡£')
      .setVersion('1.0')
      .addBearerAuth()
      .build();

    const document = SwaggerModule.createDocument(app, config);
    SwaggerModule.setup('api-docs', app, document);
  }

  const port = configService.get('app.port');
  await app.listen(port, '0.0.0.0');

  logger.log(`åº”ç”¨è¿è¡Œåœ¨ç«¯å£ ${port}`);
  logger.log(`ç¯å¢ƒ: ${process.env.NODE_ENV}`);
  logger.log(`å†…å­˜ä½¿ç”¨: ${JSON.stringify(process.memoryUsage())}`);
}

bootstrap().catch((error) => {
  console.error('åº”ç”¨å¯åŠ¨å¤±è´¥:', error);
  process.exit(1);
});
```

### 5. é›†ç¾¤æ¨¡å¼é…ç½®

```typescript
// src/cluster.ts
import cluster from 'cluster';
import * as os from 'os';
import { Logger } from '@nestjs/common';

const logger = new Logger('Cluster');
const numCPUs = os.cpus().length;

if (cluster.isMaster) {
  logger.log(`Master process ${process.pid} is running`);
  logger.log(`Starting ${numCPUs} workers...`);

  // Fork workers
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => {
    logger.warn(`Worker ${worker.process.pid} died with code ${code} and signal ${signal}`);
    logger.log('Starting a new worker...');
    cluster.fork();
  });

  // ä¼˜é›…å…³é—­
  process.on('SIGTERM', () => {
    logger.log('Master received SIGTERM, shutting down gracefully');

    for (const id in cluster.workers) {
      cluster.workers[id].kill();
    }

    setTimeout(() => {
      logger.log('Forcing shutdown');
      process.exit(0);
    }, 10000);
  });

} else {
  // Worker process
  require('./main');
  logger.log(`Worker ${process.pid} started`);
}
```

### 6. å†…å­˜å’Œæ€§èƒ½ç›‘æ§

```typescript
// src/monitoring/performance.service.ts
import { Injectable, Logger } from '@nestjs/common';
import { Cron, CronExpression } from '@nestjs/schedule';
import * as os from 'os';

@Injectable()
export class PerformanceService {
  private readonly logger = new Logger(PerformanceService.name);

  @Cron(CronExpression.EVERY_MINUTE)
  logSystemMetrics() {
    const memoryUsage = process.memoryUsage();
    const cpuUsage = process.cpuUsage();
    const systemLoad = os.loadavg();
    const freeMemory = os.freemem();
    const totalMemory = os.totalmem();

    const metrics = {
      timestamp: new Date().toISOString(),
      memory: {
        rss: Math.round(memoryUsage.rss / 1024 / 1024), // MB
        heapUsed: Math.round(memoryUsage.heapUsed / 1024 / 1024), // MB
        heapTotal: Math.round(memoryUsage.heapTotal / 1024 / 1024), // MB
        external: Math.round(memoryUsage.external / 1024 / 1024), // MB
      },
      cpu: {
        user: cpuUsage.user,
        system: cpuUsage.system,
      },
      system: {
        loadAverage: systemLoad,
        freeMemory: Math.round(freeMemory / 1024 / 1024), // MB
        totalMemory: Math.round(totalMemory / 1024 / 1024), // MB
        memoryUsagePercent: Math.round(((totalMemory - freeMemory) / totalMemory) * 100),
      },
      uptime: process.uptime(),
    };

    // è®°å½•è­¦å‘Šçº§åˆ«çš„æŒ‡æ ‡
    if (metrics.memory.heapUsed > 500) { // è¶…è¿‡500MB
      this.logger.warn(`High memory usage: ${metrics.memory.heapUsed}MB`);
    }

    if (metrics.system.memoryUsagePercent > 80) { // ç³»ç»Ÿå†…å­˜ä½¿ç”¨è¶…è¿‡80%
      this.logger.warn(`High system memory usage: ${metrics.system.memoryUsagePercent}%`);
    }

    if (metrics.system.loadAverage[0] > os.cpus().length) { // è´Ÿè½½è¶…è¿‡CPUæ ¸å¿ƒæ•°
      this.logger.warn(`High system load: ${metrics.system.loadAverage[0]}`);
    }

    // åœ¨å¼€å‘ç¯å¢ƒä¸‹è®°å½•è¯¦ç»†æŒ‡æ ‡
    if (process.env.NODE_ENV === 'development') {
      this.logger.debug('System metrics:', JSON.stringify(metrics, null, 2));
    }
  }

  getMetrics() {
    const memoryUsage = process.memoryUsage();
    const cpuUsage = process.cpuUsage();

    return {
      memory: memoryUsage,
      cpu: cpuUsage,
      uptime: process.uptime(),
      version: process.version,
      platform: process.platform,
      arch: process.arch,
    };
  }
}
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ

### 1. Prometheus æŒ‡æ ‡æ”¶é›†

```typescript
// src/monitoring/prometheus.service.ts
import { Injectable } from '@nestjs/common';
import { register, Counter, Histogram, Gauge } from 'prom-client';

@Injectable()
export class PrometheusService {
  private readonly httpRequestsTotal = new Counter({
    name: 'http_requests_total',
    help: 'Total number of HTTP requests',
    labelNames: ['method', 'route', 'status_code'],
  });

  private readonly httpRequestDuration = new Histogram({
    name: 'http_request_duration_seconds',
    help: 'Duration of HTTP requests in seconds',
    labelNames: ['method', 'route'],
    buckets: [0.1, 0.5, 1, 2, 5],
  });

  private readonly activeConnections = new Gauge({
    name: 'active_connections',
    help: 'Number of active connections',
  });

  private readonly databaseConnections = new Gauge({
    name: 'database_connections',
    help: 'Number of database connections',
  });

  private readonly cacheHits = new Counter({
    name: 'cache_hits_total',
    help: 'Total number of cache hits',
    labelNames: ['cache_type'],
  });

  private readonly cacheMisses = new Counter({
    name: 'cache_misses_total',
    help: 'Total number of cache misses',
    labelNames: ['cache_type'],
  });

  constructor() {
    // æ³¨å†Œé»˜è®¤æŒ‡æ ‡
    register.registerMetric(this.httpRequestsTotal);
    register.registerMetric(this.httpRequestDuration);
    register.registerMetric(this.activeConnections);
    register.registerMetric(this.databaseConnections);
    register.registerMetric(this.cacheHits);
    register.registerMetric(this.cacheMisses);
  }

  incrementHttpRequests(method: string, route: string, statusCode: number) {
    this.httpRequestsTotal.inc({ method, route, status_code: statusCode });
  }

  observeHttpRequestDuration(method: string, route: string, duration: number) {
    this.httpRequestDuration.observe({ method, route }, duration);
  }

  setActiveConnections(count: number) {
    this.activeConnections.set(count);
  }

  setDatabaseConnections(count: number) {
    this.databaseConnections.set(count);
  }

  incrementCacheHits(cacheType: string) {
    this.cacheHits.inc({ cache_type: cacheType });
  }

  incrementCacheMisses(cacheType: string) {
    this.cacheMisses.inc({ cache_type: cacheType });
  }

  getMetrics() {
    return register.metrics();
  }
}
```

### 2. ç›‘æ§ä¸­é—´ä»¶

```typescript
// src/common/middleware/monitoring.middleware.ts
import { Injectable, NestMiddleware } from '@nestjs/common';
import { Request, Response, NextFunction } from 'express';
import { PrometheusService } from '../../monitoring/prometheus.service';

@Injectable()
export class MonitoringMiddleware implements NestMiddleware {
  constructor(private prometheusService: PrometheusService) {}

  use(req: Request, res: Response, next: NextFunction) {
    const start = Date.now();

    res.on('finish', () => {
      const duration = (Date.now() - start) / 1000;
      const route = req.route?.path || req.path;

      this.prometheusService.incrementHttpRequests(
        req.method,
        route,
        res.statusCode,
      );

      this.prometheusService.observeHttpRequestDuration(
        req.method,
        route,
        duration,
      );
    });

    next();
  }
}
```

### 3. ç»“æ„åŒ–æ—¥å¿—æœåŠ¡

```typescript
// src/logging/winston-logger.service.ts
import { Injectable, LoggerService } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import * as winston from 'winston';
import * as DailyRotateFile from 'winston-daily-rotate-file';

@Injectable()
export class WinstonLoggerService implements LoggerService {
  private logger: winston.Logger;

  constructor(private configService: ConfigService) {
    this.createLogger();
  }

  private createLogger() {
    const logLevel = this.configService.get('logging.level');
    const logPath = this.configService.get('logging.logFilePath');
    const maxFiles = this.configService.get('logging.maxFiles');
    const maxSize = this.configService.get('logging.maxSize');

    const transports: winston.transport[] = [];

    // æ§åˆ¶å°è¾“å‡º
    if (this.configService.get('logging.enableConsoleLogging')) {
      transports.push(
        new winston.transports.Console({
          format: winston.format.combine(
            winston.format.timestamp(),
            winston.format.colorize(),
            winston.format.printf(({ timestamp, level, message, context, trace }) => {
              return `${timestamp} [${context}] ${level}: ${message}${trace ? `\n${trace}` : ''}`;
            }),
          ),
        }),
      );
    }

    // æ–‡ä»¶è¾“å‡º
    if (this.configService.get('logging.enableFileLogging')) {
      // é”™è¯¯æ—¥å¿—
      transports.push(
        new DailyRotateFile({
          filename: `${logPath}/error-%DATE%.log`,
          datePattern: 'YYYY-MM-DD',
          level: 'error',
          maxFiles,
          maxSize,
          format: winston.format.combine(
            winston.format.timestamp(),
            winston.format.json(),
          ),
        }),
      );

      // åº”ç”¨æ—¥å¿—
      transports.push(
        new DailyRotateFile({
          filename: `${logPath}/app-%DATE%.log`,
          datePattern: 'YYYY-MM-DD',
          maxFiles,
          maxSize,
          format: winston.format.combine(
            winston.format.timestamp(),
            winston.format.json(),
          ),
        }),
      );

      // è®¿é—®æ—¥å¿—
      transports.push(
        new DailyRotateFile({
          filename: `${logPath}/access-%DATE%.log`,
          datePattern: 'YYYY-MM-DD',
          level: 'info',
          maxFiles,
          maxSize,
          format: winston.format.combine(
            winston.format.timestamp(),
            winston.format.json(),
          ),
        }),
      );
    }

    this.logger = winston.createLogger({
      level: logLevel,
      format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.errors({ stack: true }),
        winston.format.json(),
      ),
      transports,
    });
  }

  log(message: string, context?: string) {
    this.logger.info(message, { context });
  }

  error(message: string, trace?: string, context?: string) {
    this.logger.error(message, { context, trace });
  }

  warn(message: string, context?: string) {
    this.logger.warn(message, { context });
  }

  debug(message: string, context?: string) {
    this.logger.debug(message, { context });
  }

  verbose(message: string, context?: string) {
    this.logger.verbose(message, { context });
  }
}
```

### 4. é”™è¯¯è¿½è¸ªæœåŠ¡ (Sentry)

```typescript
// src/monitoring/sentry.service.ts
import { Injectable } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import * as Sentry from '@sentry/node';
import { ProfilingIntegration } from '@sentry/profiling-node';

@Injectable()
export class SentryService {
  constructor(private configService: ConfigService) {
    this.initSentry();
  }

  private initSentry() {
    const dsn = this.configService.get('sentry.dsn');
    if (!dsn) return;

    Sentry.init({
      dsn,
      environment: process.env.NODE_ENV,
      integrations: [
        new ProfilingIntegration(),
      ],
      tracesSampleRate: 0.1,
      profilesSampleRate: 0.1,
      beforeSend(event) {
        // è¿‡æ»¤æ•æ„Ÿä¿¡æ¯
        if (event.request?.data) {
          delete event.request.data.password;
          delete event.request.data.token;
        }
        return event;
      },
    });
  }

  captureException(error: Error, context?: any) {
    Sentry.withScope((scope) => {
      if (context) {
        scope.setContext('additional', context);
      }
      Sentry.captureException(error);
    });
  }

  captureMessage(message: string, level: Sentry.SeverityLevel = 'info') {
    Sentry.captureMessage(message, level);
  }

  addBreadcrumb(breadcrumb: Sentry.Breadcrumb) {
    Sentry.addBreadcrumb(breadcrumb);
  }

  setUser(user: { id: string; email?: string; username?: string }) {
    Sentry.setUser(user);
  }

  setTag(key: string, value: string) {
    Sentry.setTag(key, value);
  }
}
```

### 5. å…¨å±€å¼‚å¸¸è¿‡æ»¤å™¨ (å¢å¼ºç‰ˆ)

```typescript
// src/common/filters/all-exceptions.filter.ts (å¢å¼ºç‰ˆ)
import {
  ExceptionFilter,
  Catch,
  ArgumentsHost,
  HttpException,
  HttpStatus,
  Logger,
} from '@nestjs/common';
import { Request, Response } from 'express';
import { PrismaClientKnownRequestError } from '@prisma/client/runtime/library';
import { SentryService } from '../../monitoring/sentry.service';
import { WinstonLoggerService } from '../../logging/winston-logger.service';

@Catch()
export class AllExceptionsFilter implements ExceptionFilter {
  private readonly logger = new Logger(AllExceptionsFilter.name);

  constructor(
    private sentryService: SentryService,
    private winstonLogger: WinstonLoggerService,
  ) {}

  catch(exception: unknown, host: ArgumentsHost): void {
    const ctx = host.switchToHttp();
    const response = ctx.getResponse<Response>();
    const request = ctx.getRequest<Request>();

    let status = HttpStatus.INTERNAL_SERVER_ERROR;
    let message = 'Internal server error';
    let code = 'INTERNAL_ERROR';

    // HTTP å¼‚å¸¸å¤„ç†
    if (exception instanceof HttpException) {
      status = exception.getStatus();
      const exceptionResponse = exception.getResponse();

      if (typeof exceptionResponse === 'string') {
        message = exceptionResponse;
      } else if (typeof exceptionResponse === 'object') {
        message = (exceptionResponse as any).message || exception.message;
        code = (exceptionResponse as any).code || 'HTTP_ERROR';
      }
    }
    // Prisma é”™è¯¯å¤„ç†
    else if (exception instanceof PrismaClientKnownRequestError) {
      const prismaError = this.handlePrismaError(exception);
      status = prismaError.status;
      message = prismaError.message;
      code = prismaError.code;
    }
    // å…¶ä»–é”™è¯¯
    else if (exception instanceof Error) {
      message = exception.message;
      code = 'UNKNOWN_ERROR';
    }

    const errorResponse = {
      statusCode: status,
      timestamp: new Date().toISOString(),
      path: request.url,
      method: request.method,
      message,
      code,
      ...(process.env.NODE_ENV === 'development' && {
        stack: exception instanceof Error ? exception.stack : undefined,
      }),
    };

    // è®°å½•é”™è¯¯æ—¥å¿—
    const logContext = {
      statusCode: status,
      method: request.method,
      url: request.url,
      userAgent: request.get('User-Agent'),
      ip: request.ip,
      userId: (request as any).user?.id,
    };

    if (status >= 500) {
      this.winstonLogger.error(
        `${request.method} ${request.url} - ${status} - ${message}`,
        exception instanceof Error ? exception.stack : undefined,
        'AllExceptionsFilter',
      );

      // å‘é€åˆ° Sentry
      this.sentryService.captureException(
        exception instanceof Error ? exception : new Error(String(exception)),
        logContext,
      );
    } else {
      this.winstonLogger.warn(
        `${request.method} ${request.url} - ${status} - ${message}`,
        'AllExceptionsFilter',
      );
    }

    response.status(status).json(errorResponse);
  }

  private handlePrismaError(error: PrismaClientKnownRequestError) {
    switch (error.code) {
      case 'P2002':
        return {
          status: HttpStatus.CONFLICT,
          message: 'æ•°æ®å·²å­˜åœ¨',
          code: 'DUPLICATE_ERROR',
        };
      case 'P2025':
        return {
          status: HttpStatus.NOT_FOUND,
          message: 'è®°å½•ä¸å­˜åœ¨',
          code: 'NOT_FOUND',
        };
      case 'P2003':
        return {
          status: HttpStatus.BAD_REQUEST,
          message: 'å¤–é”®çº¦æŸå¤±è´¥',
          code: 'FOREIGN_KEY_ERROR',
        };
      default:
        return {
          status: HttpStatus.INTERNAL_SERVER_ERROR,
          message: 'æ•°æ®åº“æ“ä½œå¤±è´¥',
          code: 'DATABASE_ERROR',
        };
    }
  }
}
```

### 6. ç›‘æ§ä»ªè¡¨æ¿é…ç½®

```yaml
# docker/grafana/dashboard.json
{
  "dashboard": {
    "id": null,
    "title": "NestJS åº”ç”¨ç›‘æ§",
    "tags": ["nestjs", "monitoring"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "HTTP è¯·æ±‚æ€»æ•°",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[5m]))",
            "legendFormat": "è¯·æ±‚/ç§’"
          }
        ]
      },
      {
        "id": 2,
        "title": "HTTP è¯·æ±‚å»¶è¿Ÿ",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          }
        ]
      },
      {
        "id": 3,
        "title": "å†…å­˜ä½¿ç”¨æƒ…å†µ",
        "type": "graph",
        "targets": [
          {
            "expr": "process_resident_memory_bytes",
            "legendFormat": "RSS Memory"
          },
          {
            "expr": "nodejs_heap_size_used_bytes",
            "legendFormat": "Heap Used"
          }
        ]
      },
      {
        "id": 4,
        "title": "æ•°æ®åº“è¿æ¥",
        "type": "stat",
        "targets": [
          {
            "expr": "database_connections",
            "legendFormat": "è¿æ¥æ•°"
          }
        ]
      },
      {
        "id": 5,
        "title": "ç¼“å­˜å‘½ä¸­ç‡",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(cache_hits_total[5m]) / (rate(cache_hits_total[5m]) + rate(cache_misses_total[5m])) * 100",
            "legendFormat": "å‘½ä¸­ç‡ %"
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "5s"
  }
}
```

## ğŸš€ å®Œæ•´éƒ¨ç½²æµç¨‹

### 1. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# scripts/production-deploy.sh

set -e

echo "ğŸš€ å¼€å§‹ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²..."

# æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
required_vars=("JWT_SECRET" "JWT_REFRESH_SECRET" "DB_PASSWORD" "MAIL_PASSWORD")
for var in "${required_vars[@]}"; do
    if [ -z "${!var}" ]; then
        echo "âŒ ç¯å¢ƒå˜é‡ $var æœªè®¾ç½®"
        exit 1
    fi
done

# åˆ›å»ºå¿…è¦çš„ç›®å½•
echo "ğŸ“ åˆ›å»ºç›®å½•ç»“æ„..."
mkdir -p /opt/blog-app/{logs,uploads,backups,ssl}
mkdir -p /opt/blog-app/docker/{nginx,mysql}

# è®¾ç½®æƒé™
chown -R 1001:1001 /opt/blog-app/uploads
chown -R 1001:1001 /opt/blog-app/logs

# å¤åˆ¶é…ç½®æ–‡ä»¶
echo "ğŸ“‹ å¤åˆ¶é…ç½®æ–‡ä»¶..."
cp docker/nginx/nginx.conf /opt/blog-app/docker/nginx/
cp docker/mysql/init.sql /opt/blog-app/docker/mysql/
cp .env.production /opt/blog-app/.env

# ç”Ÿæˆ SSL è¯ä¹¦ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
if [ ! -f "/opt/blog-app/ssl/cert.pem" ]; then
    echo "ğŸ” ç”Ÿæˆ SSL è¯ä¹¦..."
    openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
        -keyout /opt/blog-app/ssl/key.pem \
        -out /opt/blog-app/ssl/cert.pem \
        -subj "/C=CN/ST=State/L=City/O=Organization/CN=localhost"
fi

# æ‹‰å–æœ€æ–°é•œåƒ
echo "ğŸ“¦ æ‹‰å– Docker é•œåƒ..."
cd /opt/blog-app
docker-compose pull

# æ•°æ®åº“å¤‡ä»½
if docker-compose ps db | grep -q "Up"; then
    echo "ğŸ’¾ å¤‡ä»½æ•°æ®åº“..."
    BACKUP_FILE="backup_$(date +%Y%m%d_%H%M%S).sql"
    docker-compose exec -T db mysqldump -u root -p$MYSQL_ROOT_PASSWORD blog_prod > backups/$BACKUP_FILE
    echo "âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ: $BACKUP_FILE"
fi

# å¯åŠ¨æœåŠ¡
echo "ğŸ”„ å¯åŠ¨æœåŠ¡..."
docker-compose up -d --remove-orphans

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# è¿è¡Œæ•°æ®åº“è¿ç§»
echo "ğŸ—„ï¸ è¿è¡Œæ•°æ®åº“è¿ç§»..."
docker-compose exec app npx prisma migrate deploy

# å¥åº·æ£€æŸ¥
echo "ğŸ¥ æ‰§è¡Œå¥åº·æ£€æŸ¥..."
max_attempts=10
attempt=1

while [ $attempt -le $max_attempts ]; do
    if curl -f http://localhost/health; then
        echo "âœ… å¥åº·æ£€æŸ¥é€šè¿‡"
        break
    else
        echo "â³ å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œé‡è¯• $attempt/$max_attempts"
        sleep 10
        ((attempt++))
    fi
done

if [ $attempt -gt $max_attempts ]; then
    echo "âŒ å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œéƒ¨ç½²å¯èƒ½æœ‰é—®é¢˜"
    exit 1
fi

# æ¸…ç†æ—§é•œåƒ
echo "ğŸ§¹ æ¸…ç†æ—§é•œåƒ..."
docker image prune -f

echo "âœ… ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å®Œæˆï¼"
echo "ğŸŒ åº”ç”¨è®¿é—®åœ°å€: https://localhost"
echo "ğŸ“Š ç›‘æ§åœ°å€: https://localhost/metrics"
echo "ğŸ“š API æ–‡æ¡£: https://localhost/api-docs"
```

### 2. ç›‘æ§éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# scripts/monitoring-deploy.sh

set -e

echo "ğŸ“Š éƒ¨ç½²ç›‘æ§ç³»ç»Ÿ..."

# åˆ›å»ºç›‘æ§ç›®å½•
mkdir -p /opt/monitoring/{prometheus,grafana,alertmanager}

# Prometheus é…ç½®
cat > /opt/monitoring/prometheus/prometheus.yml << EOF
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'nestjs-app'
    static_configs:
      - targets: ['app:9090']
    scrape_interval: 5s
    metrics_path: /metrics

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  - job_name: 'mysql-exporter'
    static_configs:
      - targets: ['mysql-exporter:9104']

  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']
EOF

# å‘Šè­¦è§„åˆ™
cat > /opt/monitoring/prometheus/alert_rules.yml << EOF
groups:
  - name: nestjs-app
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status_code=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ \$value }} errors per second"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ \$value }} seconds"

      - alert: HighMemoryUsage
        expr: (nodejs_heap_size_used_bytes / nodejs_heap_size_total_bytes) > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ \$value | humanizePercentage }}"

      - alert: DatabaseConnectionsHigh
        expr: database_connections > 8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "Database connections: {{ \$value }}"
EOF

# å¯åŠ¨ç›‘æ§æœåŠ¡
docker-compose -f docker-compose.monitoring.yml up -d

echo "âœ… ç›‘æ§ç³»ç»Ÿéƒ¨ç½²å®Œæˆï¼"
echo "ğŸ“Š Prometheus: http://localhost:9090"
echo "ğŸ“ˆ Grafana: http://localhost:3001 (admin/admin)"
```

### 3. ç›‘æ§ Docker Compose

```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - /opt/monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - /opt/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - /opt/monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - /opt/monitoring/alertmanager:/etc/alertmanager
    networks:
      - monitoring

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring

  mysql-exporter:
    image: prom/mysqld-exporter:latest
    container_name: mysql-exporter
    ports:
      - "9104:9104"
    environment:
      - DATA_SOURCE_NAME=nestjs:password@(db:3306)/blog_prod
    networks:
      - monitoring
      - app-network

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://redis:6379
    networks:
      - monitoring
      - app-network

volumes:
  prometheus_data:
  grafana_data:

networks:
  monitoring:
    driver: bridge
  app-network:
    external: true
```

### 4. è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬

```bash
#!/bin/bash
# scripts/maintenance.sh

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
APP_DIR="/opt/blog-app"

# æ—¥å¿—æ¸…ç†
cleanup_logs() {
    echo "ğŸ§¹ æ¸…ç†æ—§æ—¥å¿—..."
    find $APP_DIR/logs -name "*.log" -mtime +30 -delete
    echo "âœ… æ—¥å¿—æ¸…ç†å®Œæˆ"
}

# æ•°æ®åº“å¤‡ä»½
backup_database() {
    echo "ğŸ’¾ å¤‡ä»½æ•°æ®åº“..."
    BACKUP_FILE="$APP_DIR/backups/backup_$(date +%Y%m%d_%H%M%S).sql"
    docker-compose -f $APP_DIR/docker-compose.yml exec -T db \
        mysqldump -u root -p$MYSQL_ROOT_PASSWORD blog_prod > $BACKUP_FILE

    # å‹ç¼©å¤‡ä»½æ–‡ä»¶
    gzip $BACKUP_FILE

    # åˆ é™¤30å¤©å‰çš„å¤‡ä»½
    find $APP_DIR/backups -name "*.sql.gz" -mtime +30 -delete

    echo "âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ: $BACKUP_FILE.gz"
}

# ç³»ç»Ÿèµ„æºæ£€æŸ¥
check_resources() {
    echo "ğŸ” æ£€æŸ¥ç³»ç»Ÿèµ„æº..."

    # ç£ç›˜ç©ºé—´æ£€æŸ¥
    DISK_USAGE=$(df / | awk 'NR==2 {print $5}' | sed 's/%//')
    if [ $DISK_USAGE -gt 80 ]; then
        echo "âš ï¸  ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: ${DISK_USAGE}%"
    fi

    # å†…å­˜ä½¿ç”¨æ£€æŸ¥
    MEMORY_USAGE=$(free | awk 'NR==2{printf "%.0f", $3*100/$2}')
    if [ $MEMORY_USAGE -gt 80 ]; then
        echo "âš ï¸  å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: ${MEMORY_USAGE}%"
    fi

    # Docker å®¹å™¨çŠ¶æ€æ£€æŸ¥
    UNHEALTHY_CONTAINERS=$(docker ps --filter "health=unhealthy" -q | wc -l)
    if [ $UNHEALTHY_CONTAINERS -gt 0 ]; then
        echo "âš ï¸  å‘ç° $UNHEALTHY_CONTAINERS ä¸ªä¸å¥åº·çš„å®¹å™¨"
        docker ps --filter "health=unhealthy"
    fi

    echo "âœ… ç³»ç»Ÿèµ„æºæ£€æŸ¥å®Œæˆ"
}

# æ€§èƒ½ä¼˜åŒ–
optimize_performance() {
    echo "âš¡ æ‰§è¡Œæ€§èƒ½ä¼˜åŒ–..."

    # æ¸…ç† Docker ç³»ç»Ÿ
    docker system prune -f

    # é‡å¯åº”ç”¨ï¼ˆå¦‚æœå†…å­˜ä½¿ç”¨è¿‡é«˜ï¼‰
    MEMORY_USAGE=$(free | awk 'NR==2{printf "%.0f", $3*100/$2}')
    if [ $MEMORY_USAGE -gt 90 ]; then
        echo "ğŸ”„ å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œé‡å¯åº”ç”¨..."
        docker-compose -f $APP_DIR/docker-compose.yml restart app
    fi

    echo "âœ… æ€§èƒ½ä¼˜åŒ–å®Œæˆ"
}

# å®‰å…¨æ›´æ–°æ£€æŸ¥
security_updates() {
    echo "ğŸ”’ æ£€æŸ¥å®‰å…¨æ›´æ–°..."

    # æ›´æ–°ç³»ç»ŸåŒ…
    apt update && apt list --upgradable | grep -i security

    # æ£€æŸ¥ Docker é•œåƒæ›´æ–°
    docker-compose -f $APP_DIR/docker-compose.yml pull

    echo "âœ… å®‰å…¨æ›´æ–°æ£€æŸ¥å®Œæˆ"
}

# ä¸»å‡½æ•°
main() {
    case "$1" in
        "logs")
            cleanup_logs
            ;;
        "backup")
            backup_database
            ;;
        "check")
            check_resources
            ;;
        "optimize")
            optimize_performance
            ;;
        "security")
            security_updates
            ;;
        "all")
            cleanup_logs
            backup_database
            check_resources
            optimize_performance
            ;;
        *)
            echo "ä½¿ç”¨æ–¹æ³•: $0 {logs|backup|check|optimize|security|all}"
            exit 1
            ;;
    esac
}

main "$@"
```

### 5. Crontab å®šæ—¶ä»»åŠ¡

```bash
# æ·»åŠ åˆ° crontab
# crontab -e

# æ¯å¤©å‡Œæ™¨2ç‚¹å¤‡ä»½æ•°æ®åº“
0 2 * * * /opt/blog-app/scripts/maintenance.sh backup

# æ¯å¤©å‡Œæ™¨3ç‚¹æ¸…ç†æ—¥å¿—
0 3 * * * /opt/blog-app/scripts/maintenance.sh logs

# æ¯å°æ—¶æ£€æŸ¥ç³»ç»Ÿèµ„æº
0 * * * * /opt/blog-app/scripts/maintenance.sh check

# æ¯å‘¨æ—¥å‡Œæ™¨4ç‚¹æ‰§è¡Œå®Œæ•´ç»´æŠ¤
0 4 * * 0 /opt/blog-app/scripts/maintenance.sh all

# æ¯å¤©æ£€æŸ¥å®‰å…¨æ›´æ–°
0 6 * * * /opt/blog-app/scripts/maintenance.sh security
```

## ğŸ‰ å°ç»“

åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å®Œæˆäº†ï¼š

### âœ… å®¹å™¨åŒ–éƒ¨ç½²
- Docker å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–
- Docker Compose ç”Ÿäº§ç¯å¢ƒé…ç½®
- Nginx åå‘ä»£ç†å’Œè´Ÿè½½å‡è¡¡
- SSL/TLS å®‰å…¨é…ç½®

### âœ… CI/CD æµæ°´çº¿
- GitHub Actions è‡ªåŠ¨åŒ–éƒ¨ç½²
- ä»£ç è´¨é‡æ£€æŸ¥å’Œæµ‹è¯•
- å®‰å…¨æ‰«æå’Œæ¼æ´æ£€æµ‹
- è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬

### âœ… æ€§èƒ½ä¼˜åŒ–
- Redis ç¼“å­˜ç­–ç•¥
- æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–
- å“åº”å‹ç¼©å’Œé™æ€èµ„æºä¼˜åŒ–
- é›†ç¾¤æ¨¡å¼é…ç½®

### âœ… ç›‘æ§å’Œæ—¥å¿—
- Prometheus æŒ‡æ ‡æ”¶é›†
- Grafana å¯è§†åŒ–ç›‘æ§
- ç»“æ„åŒ–æ—¥å¿—è®°å½•
- Sentry é”™è¯¯è¿½è¸ª

### âœ… è¿ç»´è‡ªåŠ¨åŒ–
- å¥åº·æ£€æŸ¥å’Œè‡ªæ„ˆæœºåˆ¶
- è‡ªåŠ¨åŒ–å¤‡ä»½å’Œæ¢å¤
- ç³»ç»Ÿèµ„æºç›‘æ§
- å®šæ—¶ç»´æŠ¤ä»»åŠ¡

è¿™å¥—å®Œæ•´çš„éƒ¨ç½²å’Œè¿ç»´æ–¹æ¡ˆç¡®ä¿äº†åº”ç”¨åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„é«˜å¯ç”¨æ€§ã€é«˜æ€§èƒ½å’Œå¯ç»´æŠ¤æ€§ã€‚

åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†å¯¹æ•´ä¸ªé¡¹ç›®è¿›è¡Œæ€»ç»“ï¼Œå¹¶æä¾›æ‰©å±•å»ºè®®å’Œæœ€ä½³å®è·µã€‚
